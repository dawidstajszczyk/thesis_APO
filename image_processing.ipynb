{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dawidstajszczyk/thesis_APO/blob/main/image_processing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ekstrakcja danych ze strony: https://www.kaggle.com/datasets/dawidstajszczyk00/dice-r0ll"
      ],
      "metadata": {
        "id": "MuyvRAROwLMA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "import os\n",
        "from google.colab import drive\n",
        "\n",
        "# Montuj Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Skopiuj plik kaggle.json do środowiska Colab\n",
        "!cp '/content/drive/MyDrive/kaggle/kaggle.json' '/content'\n",
        "os.environ['KAGGLE_CONFIG_DIR'] = \"/content\"\n",
        "\n",
        "# Pobierz zestaw danych\n",
        "!kaggle datasets download -d dawidstajszczyk00/dice-r0ll\n",
        "\n",
        "# Ścieżka do katalogu, gdzie znajduje się pobrany plik ZIP\n",
        "zip_file_path = '/content/dice-r0ll.zip'\n",
        "\n",
        "# Katalog docelowy dla rozpakowwanych danych\n",
        "extracted_folder_path = '/content/extracted_images'\n",
        "\n",
        "# Rozpakuj plik ZIP\n",
        "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extracted_folder_path)"
      ],
      "metadata": {
        "id": "pu-WhzzuwNPP",
        "outputId": "8227511b-0909-4425-f63b-03e86c8e66e6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "dice-r0ll.zip: Skipping, found more recently modified local copy (use --force to force download)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Przetwarzanie obrazów"
      ],
      "metadata": {
        "id": "rI-ur2-bwgv_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "def count_black_dots(image_path):\n",
        "    # Wczytanie obrazu\n",
        "    image = cv2.imread(image_path)\n",
        "\n",
        "    # Przekształcenie obrazu na odcienie szarości\n",
        "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Rozmycie Gaussowskie w celu wygładzenia krawędzi\n",
        "    blurred = cv2.GaussianBlur(gray, (5, 5), 0)\n",
        "\n",
        "    # Binaryzacja obrazu (czarne kropki będą miały wartość 0)\n",
        "    _, binary = cv2.threshold(gray, 40, 255, cv2.THRESH_BINARY)\n",
        "\n",
        "    # Detekcja krawędzi w obrazie\n",
        "    edges = cv2.Canny(binary, 50, 150)\n",
        "\n",
        "    # Zastosowanie dylatacji w celu połączenia ewentualnych przerw w krawędziach\n",
        "    kernel = np.ones((5, 5), np.uint8)\n",
        "    dilated = cv2.dilate(edges, kernel, iterations=1)\n",
        "\n",
        "    # Utworzenie kopii obrazu, na którym będą rysowane kontury czarnych kropek\n",
        "    dots_image = dilated.copy()\n",
        "\n",
        "    # Znalezienie konturów w obrazie\n",
        "    contours, _ = cv2.findContours(dilated, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "\n",
        "    # Rysowanie konturów\n",
        "    cv2.drawContours(dots_image, contours, -1, (0, 255, 0), 2)\n",
        "\n",
        "    # Zliczenie czarnych kropek na podstawie pola powierzchni i kolistości\n",
        "    black_dot_count = 0\n",
        "    for contour in contours:\n",
        "        area = cv2.contourArea(contour)\n",
        "        if area < 100:  # Minimalna wielkość obszaru, aby uznać go za czarną kropkę\n",
        "            continue\n",
        "\n",
        "        # Sprawdzenie, czy kontur jest zbliżony do kształtu okręgu\n",
        "        perimeter = cv2.arcLength(contour, True)\n",
        "        circularity = 4 * np.pi * area / (perimeter * perimeter)\n",
        "        if circularity > 0.8:  # Określ próg, powyżej którego uznajemy kształt za okrągły\n",
        "            black_dot_count += 1\n",
        "\n",
        "    return black_dot_count, dots_image"
      ],
      "metadata": {
        "id": "2jnFUvjfwjGE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZUVlT1XxmI3M"
      },
      "outputs": [],
      "source": [
        "from skimage import io, color\n",
        "import shutil\n",
        "\n",
        "# Wyczyść workspace\n",
        "folder_path = '/content/extracted_images/processed_images'\n",
        "shutil.rmtree(folder_path, ignore_errors=True)\n",
        "\n",
        "# Ścieżka do foldera zawierającego klasy\n",
        "base_path = '/content/extracted_images/dataset/'\n",
        "\n",
        "# Lista klas\n",
        "classes = ['1', '2', '3', '4', '5', '6']\n",
        "\n",
        "# Ścieżka, w którym zostaną umieszczone przetworzone obrazy\n",
        "processed_path = '/content/extracted_images/processed_images/'\n",
        "\n",
        "# Utwórz folder processed_images, jeśli nie istnieje\n",
        "os.makedirs(processed_path, exist_ok=True)\n",
        "\n",
        "for class_label in classes:\n",
        "    class_path = os.path.join(base_path, class_label)\n",
        "    image_files = os.listdir(class_path)\n",
        "\n",
        "    for image_file in image_files:\n",
        "        image_path = os.path.join(class_path, image_file)\n",
        "\n",
        "        # Sprawdź, czy ścieżka prowadzi do pliku, a nie katalogu\n",
        "        if os.path.isfile(image_path):\n",
        "            # Wczytaj obraz\n",
        "            processed_image = io.imread(image_path)\n",
        "\n",
        "            # Przetwórz obraz\n",
        "            dots_count, processed_image = count_black_dots(image_path)\n",
        "            print(\"Liczba czarnych kropek:\", dots_count)\n",
        "\n",
        "            # Utwórz ścieżkę dla obrazu przetworzonego\n",
        "            processed_image_path = os.path.join(processed_path, class_label, image_file)\n",
        "\n",
        "            # Utwórz folder dla obrazów przetworzonych, jeśli nie istnieje\n",
        "            os.makedirs(os.path.join(processed_path, class_label), exist_ok=True)\n",
        "\n",
        "            # Zapisz przetworzony obraz w folderze processed_images\n",
        "            #io.imsave(processed_image_path, (processed_image * 255).astype(np.uint8), check_contrast=False)\n",
        "            io.imsave(processed_image_path, processed_image.astype(np.uint8), check_contrast=False)\n",
        "        else:\n",
        "          print(\"Incorrect file\")\n",
        "\n",
        "\n",
        "print(\"Images processed and saved to processed_images folder\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "import os\n",
        "import random\n",
        "\n",
        "# Lista zawierająca pełne ścieżki do folderów klas\n",
        "class_paths = [os.path.join(processed_path, class_name) for class_name in classes]\n",
        "\n",
        "# Ścieżka do foldera testowego\n",
        "test_path = os.path.join(processed_path, \"test\")\n",
        "\n",
        "# Utwórz folder testowy, jeśli nie istnieje\n",
        "os.makedirs(test_path, exist_ok=True)\n",
        "\n",
        "\n",
        "# Podział każdego folderu klasy na zbiór treningowy i testowy\n",
        "for class_path in class_paths:\n",
        "    images = os.listdir(class_path)\n",
        "    _, test_images = train_test_split(images, test_size=0.02, random_state=42)\n",
        "\n",
        "    # Utwórz folder treningowy, jeśli nie istnieje\n",
        "    os.makedirs(train_path, exist_ok=True)\n",
        "\n",
        "    # Przenieś odpowiednie obrazy do folderu testowego\n",
        "    for test_image in test_images:\n",
        "        src_path = os.path.join(class_path, test_image)\n",
        "        dest_path = os.path.join(test_path, test_image)\n",
        "        os.rename(src_path, dest_path)\n",
        "\n",
        "# Po dodaniu obrazów do zbioru testowego, wymieszaj je\n",
        "test_images = os.listdir(test_path)\n",
        "random.shuffle(test_images)"
      ],
      "metadata": {
        "id": "RJfPmV8S7PsD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "v4Y7d3au7Ffj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Proces przetwarzania obrazów:\n",
        "1. Ładowanie obrazu\n",
        "2. Konwersja do skali szarości\n",
        "3. Rozmycie Gaussowskie\n",
        "4. Binaryzacja obrazu\n",
        "5. Detekcja krawędzi\n",
        "6. Dylatacja\n",
        "7. Znalezenie konturów\n",
        "7. Klasyfikacja konturów na podstawie obszaru i kolistości"
      ],
      "metadata": {
        "id": "BwmSMEpbuHzO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Co dalej?\n",
        "1. Stworzyć nowy dataset z różnorodnym tłem - 100 zdjęć na klasę\n",
        "2. Użyć 2-3% zbioru na klasyfikację wykorzystującą APO.\n",
        "\t- podzielić dane na zbiór treningowy/testowy (chyba najprościej)\n",
        "\t- pomieszać dane przed podziałem\n",
        "\t- wykonać klasyfikację\n",
        "\t- sprawdzić dokładność ręcznie lub jak jest czas zautomatyzować to.\n",
        "3. Użyć 100% zbioru do treningu i klasyfikacji wykorzystującą ML.\n"
      ],
      "metadata": {
        "id": "Z5Hrsh6_J4jx"
      }
    }
  ]
}